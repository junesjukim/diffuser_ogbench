diff --git a/diffuser/scripts/train_values.py b/diffuser/scripts/train_values.py
index 3d9c84c..6eef6dc 100644
--- a/diffuser/scripts/train_values.py
+++ b/diffuser/scripts/train_values.py
@@ -21,8 +21,8 @@ print("Active conda environment:", conda_env)
 class Parser(utils.Parser):
     dataset: str = 'walker2d-medium-replay-v2'
     config: str = 'config.locomotion'
-    q_path: str = '/home/junseolee/intern/diffuser_ogbench/iql-pytorch/runs/ogbench_runs/task1/test-task1-06-08-16-31-bs256-s0-t3.0-e0.7/model/critic_s470000.pth'
-    v_path: str = '/home/junseolee/intern/diffuser_ogbench/iql-pytorch/runs/ogbench_runs/task1/test-task1-06-08-16-31-bs256-s0-t3.0-e0.7/model/value_s470000.pth'
+    q_path: str = '/home/junseolee/intern/diffuser_ogbench/iql_pytorch/runs/ogbench_runs/task1/test-task1-06-08-16-31-bs256-s0-t3.0-e0.7/model/critic_s700000.pth'
+    v_path: str = '/home/junseolee/intern/diffuser_ogbench/iql_pytorch/runs/ogbench_runs/task1/test-task1-06-08-16-31-bs256-s0-t3.0-e0.7/model/value_s700000.pth'
 
 args = Parser().parse_args('values')
 set_model_mode(args.prefix)
diff --git a/iql_pytorch/actor.py b/iql_pytorch/actor.py
deleted file mode 100644
index d63b5ae..0000000
--- a/iql_pytorch/actor.py
+++ /dev/null
@@ -1,32 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.distributions
-from common import MLP
-
-
-class Actor(nn.Module):
-    """MLP actor network."""
-
-    def __init__(
-        self, state_dim, action_dim, hidden_dim, n_layers, dropout_rate=None,
-        log_std_min=-10.0, log_std_max=2.0,
-    ):
-        super().__init__()
-
-        self.mlp = MLP(
-            state_dim, 2 * action_dim, hidden_dim, n_layers, dropout_rate=dropout_rate
-        )
-
-        self.log_std_min = log_std_min
-        self.log_std_max = log_std_max
-
-    def forward(
-        self, states
-    ):
-        mu, log_std = self.mlp(states).chunk(2, dim=-1)
-        mu = torch.tanh(mu)
-        return mu
-
-    def get_action(self, states):
-        mu = self.forward(states)
-        return mu
diff --git a/iql_pytorch/common.py b/iql_pytorch/common.py
deleted file mode 100644
index 10943b9..0000000
--- a/iql_pytorch/common.py
+++ /dev/null
@@ -1,41 +0,0 @@
-import torch.nn as nn
-from typing import Callable, Optional
-
-from torch.nn.modules.dropout import Dropout
-
-
-class MLP(nn.Module):
-
-    def __init__(
-        self,
-        in_dim,
-        out_dim,
-        hidden_dim,
-        n_layers,
-        activations: Callable = nn.ReLU,
-        activate_final: int = False,
-        dropout_rate: Optional[float] = None
-    ) -> None:
-        super().__init__()
-
-        self.affines = []
-        self.affines.append(nn.Linear(in_dim, hidden_dim))
-        for i in range(n_layers-2):
-            self.affines.append(nn.Linear(hidden_dim, hidden_dim))
-        self.affines.append(nn.Linear(hidden_dim, out_dim))
-        self.affines = nn.ModuleList(self.affines)
-
-        self.activations = activations()
-        self.activate_final = activate_final
-        self.dropout_rate = dropout_rate
-        if dropout_rate is not None:
-            self.dropout = Dropout(self.dropout_rate)
-
-    def forward(self, x):
-        for i in range(len(self.affines)):
-            x = self.affines[i](x)
-            if i != len(self.affines)-1 or self.activate_final:
-                x = self.activations(x)
-                if self.dropout_rate is not None:
-                    x = self.dropout(x)
-        return x
diff --git a/iql_pytorch/critic.py b/iql_pytorch/critic.py
deleted file mode 100644
index 14d9821..0000000
--- a/iql_pytorch/critic.py
+++ /dev/null
@@ -1,59 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-
-from common import MLP
-
-
-class ValueCritic(nn.Module):
-    def __init__(
-        self,
-        in_dim,
-        hidden_dim,
-        n_layers,
-        **kwargs
-    ) -> None:
-        super().__init__()
-        self.mlp = MLP(in_dim, 1, hidden_dim, n_layers, **kwargs)
-
-    def forward(self, state):
-        return self.mlp(state)
-
-
-class Critic(nn.Module):
-    """
-    From TD3+BC
-    """
-
-    def __init__(self, state_dim, action_dim):
-        super(Critic, self).__init__()
-
-        # Q1 architecture
-        self.l1 = nn.Linear(state_dim + action_dim, 256)
-        self.l2 = nn.Linear(256, 256)
-        self.l3 = nn.Linear(256, 1)
-
-        # Q2 architecture
-        self.l4 = nn.Linear(state_dim + action_dim, 256)
-        self.l5 = nn.Linear(256, 256)
-        self.l6 = nn.Linear(256, 1)
-
-    def forward(self, state, action):
-        sa = torch.cat([state, action], 1)
-
-        q1 = F.relu(self.l1(sa))
-        q1 = F.relu(self.l2(q1))
-        q1 = self.l3(q1)
-
-        q2 = F.relu(self.l4(sa))
-        q2 = F.relu(self.l5(q2))
-        q2 = self.l6(q2)
-        return q1, q2
-
-    def Q1(self, state, action):
-        sa = torch.cat([state, action], 1)
-
-        q1 = F.relu(self.l1(sa))
-        q1 = F.relu(self.l2(q1))
-        q1 = self.l3(q1)
-        return q1